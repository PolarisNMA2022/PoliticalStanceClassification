{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Classify_political_orientation_using_pretrained_model.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU",
    "gpuClass": "standard"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Classify your text's political stance using pretrained models.\n",
        "\n",
        "This notes let you classify your own text using pre-trained neural network with BERT layer, and neural network with Longformer layer. (Unfortunately, we have lost the pretrained model of MLP with fasttext.)\n",
        "\n",
        "First of all, downloads all 'pkl' files from [this link](https://drive.google.com/drive/folders/11sa5UQrHWCLSmS9mHN36JfFrB7BLmf9z?usp=sharing) and modify the path of those pickle file in below. Also, modify the path of your text file and its (expected) political stance in below."
      ],
      "metadata": {
        "id": "48WOsr21_hLw"
      }
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "id": "F3jOVtHo_dsQ"
      },
      "outputs": [],
      "source": [
        "path_pickle_files = '/content/drive/MyDrive/Data_NMA_Polaris/Trained_models/'\n",
        "path_for_text = './nyt_article.txt' # Change it with your own text files.\n",
        "political_orientation = 'left' # Choose 'left', 'center', or 'right'"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install transformers --quiet\n",
        "import pandas as pd\n",
        "import pickle\n",
        "import numpy as np\n",
        "\n",
        "# For the Transformers models\n",
        "import torch\n",
        "from transformers import BertTokenizer,LongformerModel,LongformerTokenizer\n",
        "from torch import nn"
      ],
      "metadata": {
        "id": "Gr3jBaxzNOd2"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Next, make your text as a pandas dataframe."
      ],
      "metadata": {
        "id": "JlACoC9pAvFc"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "with open(path_for_text) as f:\n",
        "    lines = f.readlines()\n",
        "    text = ' '.join(lines)\n",
        "df = pd.DataFrame([[text,political_orientation]], columns =['text', 'relative_stance']) "
      ],
      "metadata": {
        "id": "LxDe6UJNAupP"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, load BERT model first and check its result."
      ],
      "metadata": {
        "id": "ErzVvV9kCmi6"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = BertTokenizer.from_pretrained('bert-base-cased')\n",
        "labels = {'left':0,\n",
        "          'center':1,\n",
        "          'right':2,\n",
        "          }\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['relative_stance']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 512, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y\n",
        "class BertClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(BertClassifier, self).__init__()\n",
        "\n",
        "        self.bert = BertModel.from_pretrained('bert-base-cased')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer\n",
        "with open(path_pickle_files+'model_bert5_from_kaggle.pkl','rb') as f:\n",
        "  model = pickle.load(f)\n",
        "\n",
        "test = Dataset(df)\n",
        "test_dataloader = torch.utils.data.DataLoader(test)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "if use_cuda:\n",
        "  model = model.cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for test_input, test_label in test_dataloader:\n",
        "    test_label = test_label.to(device)\n",
        "    mask = test_input['attention_mask'].to(device)\n",
        "    input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "    output = model(input_id, mask)\n",
        "    result=output.argmax(dim=1).cpu().detach().numpy().tolist()[0]\n",
        "\n",
        "if (result == 0):\n",
        "  print('BERT-prediction:left')\n",
        "elif (result == 1):\n",
        "  print('BERT-prediction:center')\n",
        "else:\n",
        "  print('BERT-prediction:right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4VbQ1pNEAlCI",
        "outputId": "66faee76-4d77-47a6-bab5-47b99b801650"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "BERT-prediction:left\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Now, load Longformer model first and check its result."
      ],
      "metadata": {
        "id": "kPXHhMExOprz"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer = LongformerTokenizer.from_pretrained('allenai/longformer-base-4096')\n",
        "labels = {'left':0,\n",
        "          'center':1,\n",
        "          'right':2}\n",
        "\n",
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, df):\n",
        "\n",
        "        self.labels = [labels[label] for label in df['relative_stance']]\n",
        "        self.texts = [tokenizer(text, \n",
        "                               padding='max_length', max_length = 1000, truncation=True,\n",
        "                                return_tensors=\"pt\") for text in df['text']]\n",
        "\n",
        "    def classes(self):\n",
        "        return self.labels\n",
        "\n",
        "    def __len__(self):\n",
        "        return len(self.labels)\n",
        "\n",
        "    def get_batch_labels(self, idx):\n",
        "        # Fetch a batch of labels\n",
        "        return np.array(self.labels[idx])\n",
        "\n",
        "    def get_batch_texts(self, idx):\n",
        "        # Fetch a batch of inputs\n",
        "        return self.texts[idx]\n",
        "\n",
        "    def __getitem__(self, idx):\n",
        "\n",
        "        batch_texts = self.get_batch_texts(idx)\n",
        "        batch_y = self.get_batch_labels(idx)\n",
        "\n",
        "        return batch_texts, batch_y\n",
        "\n",
        "class LongformerClassifier(nn.Module):\n",
        "\n",
        "    def __init__(self, dropout=0.5):\n",
        "\n",
        "        super(LongformerClassifier, self).__init__()\n",
        "\n",
        "        self.bert = LongformerModel.from_pretrained('allenai/longformer-base-4096')\n",
        "        self.dropout = nn.Dropout(dropout)\n",
        "        self.linear = nn.Linear(768, 3)\n",
        "        self.relu = nn.ReLU()\n",
        "\n",
        "    def forward(self, input_id, mask):\n",
        "\n",
        "        _, pooled_output = self.bert(input_ids= input_id, attention_mask=mask,return_dict=False)\n",
        "        dropout_output = self.dropout(pooled_output)\n",
        "        linear_output = self.linear(dropout_output)\n",
        "        final_layer = self.relu(linear_output)\n",
        "\n",
        "        return final_layer\n",
        "\n",
        "\n",
        "with open(path_pickle_files+'Copy of model_Longformer0.pkl','rb') as f:\n",
        "  model = pickle.load(f)\n",
        "\n",
        "test = Dataset(df)\n",
        "test_dataloader = torch.utils.data.DataLoader(test)\n",
        "\n",
        "use_cuda = torch.cuda.is_available()\n",
        "device = torch.device(\"cuda\" if use_cuda else \"cpu\")\n",
        "\n",
        "if use_cuda:\n",
        "  model = model.cuda()\n",
        "\n",
        "with torch.no_grad():\n",
        "  for test_input, test_label in test_dataloader:\n",
        "    test_label = test_label.to(device)\n",
        "    mask = test_input['attention_mask'].to(device)\n",
        "    input_id = test_input['input_ids'].squeeze(1).to(device)\n",
        "    output = model(input_id, mask)\n",
        "    result=output.argmax(dim=1).cpu().detach().numpy().tolist()[0]\n",
        "\n",
        "if (result == 0):\n",
        "  print('Longformer-prediction:left')\n",
        "elif (result == 1):\n",
        "  print('Longformer-prediction:center')\n",
        "else:\n",
        "  print('Longformer-prediction:right')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "niW1mLhnNgWF",
        "outputId": "9d6c57be-ce43-43f7-dfee-e1feb33fe3f3"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Longformer-prediction:left\n"
          ]
        }
      ]
    }
  ]
}